
from src import config, retriever
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain, RetrievalQA
from langchain.agents import initialize_agent, Tool
from haystack.document_stores import ElasticsearchDocumentStore
from src.utils import build_message_history
import logging
import json

SUFFIX = """Begin! Take into consideration the previous chat history (if not empty): {chat_history}. Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.
Thought:"""

def make_agent():
    """
    Creates and returns an agent for chat-based conversation.
    Returns:
    - agent: An agent object for chat-based conversation.
    """

    llm = ChatOpenAI(
        openai_api_key=config.OPENAI_API_KEY,
        model_name="gpt-3.5-turbo",
        temperature=0.0,
    )

    # retrieval qa chain
    qa = RetrievalQA.from_chain_type(
        llm=llm, chain_type="stuff", retriever = retriever.make_retriever()
    )

    tools = [
        Tool(
            name="Knowledge Base",
            func=qa.run,
            description=(
                "Use this tool always first when answering complex queries about companies to get "
                "more information about the topic. Run the query exactly as written, "
                "except if previous chat history is not empty. "
                "In that case, run the query according to the previous chat history."
            ),
        ),
        Tool(
            name="BM25 Retrieval",
            func=qa.run,
            description=(
                "Use this tool IF AND ONLY IF the answer generated by the "
                "<Knowledge Base> tool does not contain relevant information for the query. "
                "Do not run the query exactly as it was written. "
                "The 'tool_input' should use relevant keywords for a BM25 algorithm. "
                "Do not omit important input details such as dates, numbers, company names or acronyms; "
                "especially if the acronyms are written between parenthesis, for example: (DOO)."
            ),
        ),
    ]

    agent = initialize_agent(
        agent="structured-chat-zero-shot-react-description",
        tools=tools,
        llm=llm,
        max_iterations=2,
        early_stopping_method="generate",
        agent_kwargs={
            "suffix": SUFFIX,
            "input_variables": ["input", "agent_scratchpad", "chat_history"],
        },
        verbose=True,
    )
    return agent

def make_agent_no_tools():
    """
    Creates and returns an agent for chat-based conversation.
    Returns:
    - agent: An agent object for chat-based conversation.

    """
        
    llm = ChatOpenAI(
        openai_api_key = config.OPENAI_API_KEY,
        model_name="gpt-3.5-turbo",
        temperature=0.0,
    )

    # retrieval qa chain
    qa = RetrievalQA.from_chain_type(
        llm=llm, chain_type="stuff", retriever = retriever.make_retriever()
    )

    tools = [
        Tool(
            name="Knowledge Base",
            func=qa.run,
            description=(
                "use this tool when answering general knowledge queries to get "
                "more information about the topic"
            ),
        )
    ]

    agent = initialize_agent(
        agent="chat-conversational-react-description",
        tools=tools,
        llm=llm,
        max_iterations=3,
        early_stopping_method="generate",
    )
    return agent

def agent_predict(agent, query: str, chat_history: str) -> str:
    """Generate an answer for the given query and chat history using an agent

    Args:
        query (str): query to run against the agent
        chat_history (str): previous message history

    Returns:
        str: answer generated by agent
    """
    chat_history_str = build_message_history(chat_history)

    # Run the agent with the query and chat history
    logging.info("Agent running")
    try:
        output = agent(
            {
                "input": query,
                "chat_history": chat_history_str,
            }
        )["output"]
        logging.info(output)

        try:
            output = json.loads(output)["action_input"]
            return output
        except ValueError:
            return output
    except:
        return "I am sorry, I cannot answer at the moment. Please try again later"



def agent_predict_no_tools(agent, query: str) -> str:
    """Generate an answer for the given query and chat history using an agent

    Args:
        query (str): query to run against the agent
        chat_history (str): previous message history

    Returns:
        str: answer generated by agent
    """

    # Run the agent with the query and chat history
    logging.info("Agent running")
    try:
        output = agent(
            {
                "input": query,
            }
        )["output"]
        logging.info(output)

        try:
            output = json.loads(output)["action_input"]
            return output
        except ValueError:
            return output
    except:
        return "I am sorry, I cannot answer at the moment. Please try again later"
